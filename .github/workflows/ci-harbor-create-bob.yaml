name: Create Harbor Bill of Behaviour on different Kernels, Kubernetes Versions, Kubernetes Distros and OSs


on:
  push:
    branches:
      - main
      - 79-create-bob-for-harbor
    paths:    
      - 'example/myharbor/**'
      - 'kubescape/**'
      - '.github/workflows/ci-harbor-create-bob.yaml'
      - 'testdata/superset.sh'
      - 'Makefile'

    

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04 ,ubuntu-24.04]
        k8s-distribution: [k3s] #, kind, minikube] #fix k0s => it is simply not reporting any anomalies IG is never loaded
        kubernetes-version: [ v1.30.0 ] #, v1.31.0, v1.32.0, v1.33.0, v1.33.2] 
    runs-on: ${{ matrix.os }}


    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Kind Cluster
        if: matrix.k8s-distribution == 'kind'
        uses: helm/kind-action@v1
        with:
          node_image: kindest/node:${{ matrix.kubernetes-version }}

      - name: Set up k3s Cluster
        if: matrix.k8s-distribution == 'k3s'
        uses: jupyterhub/action-k3s-helm@v4
        with:
          k3s-version: ${{ matrix.kubernetes-version }}+k3s1

      - name: Set up Minikube Cluster
        if: matrix.k8s-distribution == 'minikube'
        uses: medyagh/setup-minikube@master
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}
      - name: Set up Minikube Cluster
        if: matrix.k8s-distribution == 'minikube'
        run: make storage

      - name: Set up K0s Cluster
        if: matrix.k8s-distribution == 'k0s'
        run: |
          # Use K0S_VERSION to install the version from the matrix
          curl --proto '=https' --tlsv1.2 -sSf https://get.k0s.sh | sudo K0S_VERSION=${{ matrix.kubernetes-version }}+k0s.0 sh
          sudo k0s install controller --single
          sudo k0s start

          # Wait for the k0s status socket to be available to prevent race conditions
          echo "Waiting for k0s to become ready..."
          timeout=180
          while ! sudo k0s status &> /dev/null; do
            sleep 5
            timeout=$((timeout-5))
            if [ $timeout -le 0 ]; then
              echo "Timed out waiting for k0s to start"
              sudo k0s status # print last error for debugging
              exit 1
            fi
          done
          mkdir -p $HOME/.kube
          sudo k0s kubeconfig admin > $HOME/.kube/config
          make storage


      - name: Prepare MicroK8s channel
        if: matrix.k8s-distribution == 'microk8s'
        run: |
          K8S_MAJOR_MINOR=$(echo "${{ matrix.kubernetes-version }}" | cut -d. -f1,2 | sed 's/v//')
          echo "MICROK8S_CHANNEL=${K8S_MAJOR_MINOR}/stable" >> $GITHUB_ENV

      - name: Set up MicroK8s Cluster
        if: matrix.k8s-distribution == 'microk8s'
        uses: balchua/microk8s-actions@v0.3.2
        with:
          channel: ${{ env.MICROK8S_CHANNEL }}
          addons: '["dns", "hostpath-storage"]'

      - name: Verify function of k8s, kubectl, and helm
        run: |
          echo "kubeconfig: $KUBECONFIG"
          kubectl version
          kubectl get pods --all-namespaces
          uname -a

          helm version
          helm list

      - name: Install kubescape
        run: |
          make kubescape-vendor
          kubectl get all -A
          kubectl logs -n honey -l app=kubescape
          kubectl logs -n honey -l app=node-agent 
          kubectl logs -n honey -l app=storage
          kubectl logs -n honey -l app=kubevuln
          kubectl logs -n honey -l app=operator




      - name: Run helm install for harbor
        run: |
          make sample-app

      - name: Get logs
        run: | 
          sleep 15
          kubectl logs -n honey -l app=node-agent 


      - name: Get Harbor NodePort and port-forward
        run: |
          # Get the NodePort for Harbor HTTP
          NODEPORT=$(kubectl get svc harbor -n harbor -o jsonpath='{.spec.ports[?(@.port==80)].nodePort}')
          echo "Harbor NodePort is $NODEPORT"
          kubectl port-forward --namespace harbor svc/harbor $NODEPORT:80 &
          sleep 5

      - name: Run helm test
        continue-on-error: true
        run: |
          echo "Harbor12345" | docker login 127.0.0.1:30002 -u admin --password-stdin
          kubectl logs -n honey -l app=kubescape
          kubectl logs -n honey -l app=operator
          sleep 25
          kubectl logs -n honey -l app=node-agent 
          kubectl logs -l app=node-agent -n honey 

      - name: Install Robot Framework libraries
        run: |
          pip install robotframework-sshlibrary robotframework-seleniumlibrary robotframework-jsonlibrary hurry



      - name: Clone Harbor Upstream Repo
        run: |
          git clone https://github.com/goharbor/harbor.git harbor-upstream
      - name: Fill robotvars.py with runtime values
        run: |
          cd harbor-upstream/tests/e2e_setup
          cat <<EOF > robotvars.py
          SCANNER_ENDPOINT = "http://127.0.0.1:8081"
          ES_ENDPOINT =  "http://127.0.0.1:9200"
          WEBHOOK_ENDPOINT =  "http://127.0.0.1:8084"
          DISTRIBUTION_ENDPOINT =  "http://127.0.0.1:8080"
          DOCKER_USER =   "admin"
          DOCKER_PWD =  "Harbor12345"
          DRAGONFLY_AUTH_TOKEN =  "dummy_token"
          ip = "127.0.0.1"
          LOCAL_REGISTRY =  "registry.goharbor.io"
          LOCAL_REGISTRY_NAMESPACE =   "harbor-ci"
          HARBOR_PASSWORD =   "Harbor12345"
          HARBOR_ADMIN = "admin"
          OIDC_HOSTNAME =  "nightly-oidc.harbor.io"
          http_get_ca =  "true"
          ip1 = ""
          EOF

      - name: Start Harbor E2E Container NEW
        run: |
          cd harbor-upstream/tests/e2e_setup
          HARBOR_SRC_FOLDER=$(realpath ../../)    
          echo ${HARBOR_SRC_FOLDER}
          docker run --privileged -v /var/log/harbor:/var/log/harbor -v /etc/hosts:/etc/hosts -v ${HARBOR_SRC_FOLDER}:/drone -v ${HARBOR_SRC_FOLDER}/tests/harbor_ca.crt:/ca/ca.crt -v /dev/shm:/dev/shm -e NETWORK_TYPE=public -w /drone registry.goharbor.io/harbor-ci/goharbor/harbor-e2e-engine:latest-ui /bin/bash

      #- name: Copy CA Certs
      #  run: |
      #    cp /ca/ca.crt /ca/harbor_ca.crt
      - name: Run Robot Setup Test
        run: |
          robot -V harbor-upstream/tests/e2e_setup/robotvars.py harbor-upstream/tests/robot-cases/Group1-Nightly/Setup_Nightly.robot
      - name: Run Robot DB Test
        run: |
          robot -V harbor-upstream/tests/e2e_setup/robotvars.py harbor-upstream/tests/robot-cases/Group1-Nightly/Setup_Nightly.robot harbor-upstream/tests/robot-cases/Group1-Nightly/DB.robot

#     - name: Run helm test 2
#       continue-on-error: true
#       run: |
  #         make helm-redis-test
  #         kubectl logs -n honey -l app=kubescape
  #         kubectl logs -n honey -l app=operator
  #         kubectl get statefulset -n bob -o jsonpath='{.items[0].status.currentRevision}'|cut -f4 -d '-'
  #         sleep 25
  #         kubectl logs -n honey -l app=node-agent 
  #         kubectl logs -l app=node-agent -n honey 
  #     - name: Run helm test 3
  #       continue-on-error: true
  #       run: |
  #         make helm-redis-test
  #         kubectl logs -n honey -l app=kubescape
  #         kubectl logs -n honey -l app=operator
  #         kubectl get statefulset -n bob -o jsonpath='{.items[0].status.currentRevision}'|cut -f4 -d '-'
  #         sleep 25
  #         kubectl logs -n honey -l app=node-agent 
  #         kubectl logs -l app=node-agent -n honey 

  #     - name: Export Redis ApplicationProfile
  #       id: export_bob
  #       run: |
  #         echo "Waiting for Redis ApplicationProfile to be generated..."
          
  #         # First, get the statefulset's current controller revision name
  #         CONTROLLER_REVISION=$(kubectl get statefulset -n bob bob-redis-master -o jsonpath='{.status.currentRevision}')
  #         if [ -z "$CONTROLLER_REVISION" ]; then
  #           echo "::error::Could not get statefulset controller revision."
  #           exit 1
  #         fi
  #         echo "StatefulSet current revision is $CONTROLLER_REVISION"
          
  #         # The profile name is expected to be 'statefulset-<controller-revision-name>'
  #         PROFILE_NAME="statefulset-${CONTROLLER_REVISION}"
  #         echo "Expected ApplicationProfile name is $PROFILE_NAME"

  #         # Wait for the profile to be created by Kubescape's node-agent.
  #         # A simple loop with a timeout is more robust here.
  #         timeout=600 # 10 minutes
  #         while ! kubectl get applicationprofile.spdx.softwarecomposition.kubescape.io -n bob "$PROFILE_NAME" &> /dev/null; do
  #           sleep 15; timeout=$((timeout-15))
  #           if [ $timeout -le 0 ]; then
  #             echo "::error::Timed out waiting for ApplicationProfile '$PROFILE_NAME' to be created."
  #             echo "Listing available profiles in namespace bob:"; kubectl get applicationprofile -n bob; exit 1
  #           fi
  #         done
  #         echo "ApplicationProfile '$PROFILE_NAME' found."
          
  #         echo "Exporting ApplicationProfile: $PROFILE_NAME"
  #         mkdir -p bob-artifact
  #         kubectl get applicationprofile -n bob "$PROFILE_NAME" -o yaml > bob-artifact/bob-redis-${{ matrix.os }}-${{ matrix.k8s-distribution }}-${{ matrix.kubernetes-version }}.yaml
  #         echo "âœ… ApplicationProfile exported to bob-artifact/bob-redis.yaml"

  #     - name: Upload Redis BoB artifact
  #       uses: actions/upload-artifact@v4
  #       with:
  #         name: redis-bob-profile-${{ matrix.os }}-${{ matrix.k8s-distribution }}-${{ matrix.kubernetes-version }}
  #         path: bob-artifact/bob-redis-${{ matrix.os }}-${{ matrix.k8s-distribution }}-${{ matrix.kubernetes-version }}.yaml

  # package-bobs:
  #   runs-on: ubuntu-latest
  #   needs: build
  #   if: always() # Run even if some matrix jobs fail, to collect successful BoBs
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4

  #     - name: Download all BoB artifacts
  #       uses: actions/download-artifact@v4
  #       with:
  #         path: bob-artifacts

  #     - name: Create a superset
  #       run: |
  #         mkdir -p all-bobs
  #         find bob-artifacts -type f -name "*.yaml" -exec cp {} all-bobs/ \;
  #         chmod +x ./src/bashhelpers/envwrap.sh
  #         ./src/bashhelpers/envwrap.sh all-bobs

  #     - name: Print attacksurface report
  #       run: cat all-bobs/attacksurface.md

  #     - name: Package all BoBs into a tarball
  #       run: |
  #         echo "Packaging the following BoB files:"
  #         ls -R all-bobs
  #         tar -czvf redis-bobs.tar.gz -C all-bobs .

  #     - name: Upload BoB tarball
  #       uses: actions/upload-artifact@v4
  #       with:
  #         name: redis-bobs-collection
  #         path: redis-bobs.tar.gz

  #     - name: setup kind
  #       uses: helm/kind-action@v1
  #       with:
  #         node_image: kindest/node:v1.33.0

  #     - name: Test superset Bob on kind    
  #       run: |
  #         echo "kubeconfig: $KUBECONFIG"
  #         kubectl version
  #         kubectl get pods --all-namespaces
  #         uname -a
  #         helm version
  #         helm list
  #         make kubescape
  #         kubectl get all -A
  #         kubectl logs -n honey -l app=kubescape
  #         kubectl logs -n honey -l app=node-agent 
  #         kubectl logs -n honey -l app=storage
  #         kubectl logs -n honey -l app=kubevuln
  #         kubectl logs -n honey -l app=operator
  #         rm ./example/myredis-umbrella-chart/redis-bob/templates/bob.yaml
  #         cp all-bobs/*_bob.yaml ./example/myredis-umbrella-chart/redis-bob/templates/.
  #         helm dependency update example/myredis-umbrella-chart/redis-bob/
  #         helm upgrade --install bob -n bob --create-namespace ./example/myredis-umbrella-chart/redis-bob --values ./example/myredis-umbrella-chart/redis-bob/values.yaml --set bob.create=true
  #         kubectl logs -n bob pods/bob-redis-master-0 redis 
  #         kubectl logs -n honey -l app=node-agent 
  #         sleep 30

  #     - name: Run positive test
  #       continue-on-error: true
  #       run: |
  #         cat all-bobs/*_bob.yaml
  #         make helm-redis-test
  #         echo "Checking for unexpected anomalies in Kubescape logs...there should be 2"
  #         kubectl logs -n honey -l app=kubescape
  #         kubectl logs -n honey -l app=operator
  #         kubectl get statefulset -n bob -o jsonpath='{.items[0].status.currentRevision}'|cut -f4 -d '-'
  #         sleep 60
  #         kubectl logs -n honey -l app=node-agent 


  #     - name: Upload superset BoB as the new final (and tested) Bill of Behavior 
  #       uses: actions/upload-artifact@v4
  #       with:
  #         name: redis-bob-final
  #         path: all-bobs/*_bob.yaml




        
